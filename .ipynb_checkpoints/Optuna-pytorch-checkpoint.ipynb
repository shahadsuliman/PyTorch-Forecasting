{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, Optuna is used to optimize hyper-parameters, but as an example, let us directly optimize a quadratic function in an IPython shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function is what will be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    x = trial.suggest_float('x',0,1)\n",
    "    y = trial.suggest_float('y',0,1)\n",
    "    return (x-2 + y) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the value of (x−2)2. Our goal is to find the value of x that minimizes the output of the objective function. This is the “optimization.” During the optimization, Optuna repeatedly calls and evaluates the objective function with different values of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Trial object corresponds to a single execution of the objective function and is internally instantiated upon each invocation of the function.\n",
    "\n",
    "The suggest APIs (for example, suggest_float()) are called inside the objective function to obtain parameters for a trial. suggest_float() selects parameters uniformly within the range provided. In our example, from −10 to 10.\n",
    "\n",
    "To start the optimization, we create a study object and pass the objective function to method optimize() as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 21:18:25,740]\u001b[0m A new study created in memory with name: no-name-cfea0295-e993-4a8a-9c17-c24cc5a866e9\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:18:25,743]\u001b[0m Trial 0 finished with value: 1.5086828166275867 and parameters: {'x': 0.08653221865993654, 'y': 0.6851832798390528}. Best is trial 0 with value: 1.5086828166275867.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:18:25,745]\u001b[0m Trial 1 finished with value: 0.470793735864454 and parameters: {'x': 0.6112550829175928, 'y': 0.7026008098684388}. Best is trial 1 with value: 0.470793735864454.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:18:25,747]\u001b[0m Trial 2 finished with value: 1.6956906104507283 and parameters: {'x': 0.32566767869187896, 'y': 0.3721454643437573}. Best is trial 1 with value: 0.470793735864454.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:18:25,748]\u001b[0m Trial 3 finished with value: 2.0407518969141663 and parameters: {'x': 0.02991942218059418, 'y': 0.5415316997917179}. Best is trial 1 with value: 0.470793735864454.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.6112550829175928, 'y': 0.7026008098684388}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 23:33:34,556]\u001b[0m A new study created in memory with name: no-name-05e4a3b0-4c31-4377-b560-7dc05294ca29\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 23:33:34,559]\u001b[0m Trial 0 finished with value: 0.4224620415636302 and parameters: {'x': 0.8281157896717252, 'y': 0.5219134097813346}. Best is trial 0 with value: 0.4224620415636302.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 23:33:34,562]\u001b[0m Trial 1 finished with value: 0.8536605997062827 and parameters: {'x': 0.8143293286981494, 'y': 0.26173311945850075}. Best is trial 1 with value: 0.8536605997062827.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 23:33:34,563]\u001b[0m Trial 2 finished with value: 2.3746851389598636 and parameters: {'x': 0.164025351071456, 'y': 0.2949733059830345}. Best is trial 2 with value: 2.3746851389598636.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 23:33:34,565]\u001b[0m Trial 3 finished with value: 2.5604380700680793 and parameters: {'x': 0.041232570923020795, 'y': 0.358630538036691}. Best is trial 3 with value: 2.5604380700680793.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.041232570923020795, 'y': 0.358630538036691}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When used to search for hyper-parameters in machine learning, usually the objective function would return the loss or accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us clarify the terminology in Optuna as follows:\n",
    "\n",
    "Trial: A single call of the objective function\n",
    "\n",
    "Study: An optimization session, which is a set of trials\n",
    "\n",
    "Parameter: A variable whose value is to be optimized, such as x in the above example\n",
    "\n",
    "In Optuna, we use the study object to manage optimization. Method create_study() returns a study object. A study object has useful properties for analyzing the optimization outcome.\n",
    "\n",
    "To get the best parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.470793735864454"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get the best value\n",
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 0.6112550829175928, 'y': 0.7026008098684388}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best params\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=1, value=0.470793735864454, datetime_start=datetime.datetime(2020, 11, 3, 21, 18, 25, 744039), datetime_complete=datetime.datetime(2020, 11, 3, 21, 18, 25, 745036), params={'x': 0.6112550829175928, 'y': 0.7026008098684388}, distributions={'x': UniformDistribution(high=1, low=0), 'y': UniformDistribution(high=1, low=0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1, state=TrialState.COMPLETE)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best trial\n",
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=0, value=1.5086828166275867, datetime_start=datetime.datetime(2020, 11, 3, 21, 18, 25, 743040), datetime_complete=datetime.datetime(2020, 11, 3, 21, 18, 25, 743040), params={'x': 0.08653221865993654, 'y': 0.6851832798390528}, distributions={'x': UniformDistribution(high=1, low=0), 'y': UniformDistribution(high=1, low=0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE),\n",
       " FrozenTrial(number=1, value=0.470793735864454, datetime_start=datetime.datetime(2020, 11, 3, 21, 18, 25, 744039), datetime_complete=datetime.datetime(2020, 11, 3, 21, 18, 25, 745036), params={'x': 0.6112550829175928, 'y': 0.7026008098684388}, distributions={'x': UniformDistribution(high=1, low=0), 'y': UniformDistribution(high=1, low=0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1, state=TrialState.COMPLETE),\n",
       " FrozenTrial(number=2, value=1.6956906104507283, datetime_start=datetime.datetime(2020, 11, 3, 21, 18, 25, 747031), datetime_complete=datetime.datetime(2020, 11, 3, 21, 18, 25, 747031), params={'x': 0.32566767869187896, 'y': 0.3721454643437573}, distributions={'x': UniformDistribution(high=1, low=0), 'y': UniformDistribution(high=1, low=0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=2, state=TrialState.COMPLETE),\n",
       " FrozenTrial(number=3, value=2.0407518969141663, datetime_start=datetime.datetime(2020, 11, 3, 21, 18, 25, 748028), datetime_complete=datetime.datetime(2020, 11, 3, 21, 18, 25, 748028), params={'x': 0.02991942218059418, 'y': 0.5415316997917179}, distributions={'x': UniformDistribution(high=1, low=0), 'y': UniformDistribution(high=1, low=0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=3, state=TrialState.COMPLETE)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all trials \n",
    "study.trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By executing optimize() again, we can continue the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 21:22:17,820]\u001b[0m Trial 4 finished with value: 1.4578516550605316 and parameters: {'x': 0.16282839179581543, 'y': 0.6297563295777577}. Best is trial 1 with value: 0.470793735864454.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,822]\u001b[0m Trial 5 finished with value: 1.1627288295720606 and parameters: {'x': 0.918673522844393, 'y': 0.003027432561733434}. Best is trial 1 with value: 0.470793735864454.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,824]\u001b[0m Trial 6 finished with value: 0.7954999795411859 and parameters: {'x': 0.7695088836321555, 'y': 0.33858306082557843}. Best is trial 1 with value: 0.470793735864454.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,825]\u001b[0m Trial 7 finished with value: 0.2784199543587225 and parameters: {'x': 0.6730877999066328, 'y': 0.7992570529008828}. Best is trial 7 with value: 0.2784199543587225.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,827]\u001b[0m Trial 8 finished with value: 2.0740206536428203 and parameters: {'x': 0.03138077167792663, 'y': 0.5284731754361793}. Best is trial 7 with value: 0.2784199543587225.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,829]\u001b[0m Trial 9 finished with value: 0.17697138157169928 and parameters: {'x': 0.9112524774594283, 'y': 0.6680678563197058}. Best is trial 9 with value: 0.17697138157169928.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,837]\u001b[0m Trial 10 finished with value: 0.0005850131815088767 and parameters: {'x': 0.9985148023441425, 'y': 0.9772981519183378}. Best is trial 10 with value: 0.0005850131815088767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,846]\u001b[0m Trial 11 finished with value: 0.003560045642940849 and parameters: {'x': 0.9805989841665648, 'y': 0.9597348977852427}. Best is trial 10 with value: 0.0005850131815088767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,854]\u001b[0m Trial 12 finished with value: 0.00594750295702308 and parameters: {'x': 0.9569986561924559, 'y': 0.9658812883289393}. Best is trial 10 with value: 0.0005850131815088767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,862]\u001b[0m Trial 13 finished with value: 0.043399958315470784 and parameters: {'x': 0.7991795426505874, 'y': 0.9924938908355116}. Best is trial 10 with value: 0.0005850131815088767.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective,n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005850131815088767"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Optuna with deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "def get_mnist_loaders(train_batch_size,test_batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(datasets.MNIST('/files/',\n",
    "                                              train=True,download=True,\n",
    "                                              transform=transforms.Compose([\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                              ])),\n",
    "                        batch_size= train_batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(datasets.MNIST('/files/', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,test_loader = get_mnist_loaders(20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 28, 28])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = data, target \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define NN class\n",
    "\n",
    "class Net_wt(nn.Module):\n",
    "    def __init__(self,activation):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.activation = activation \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "model = Net(F.relu).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: select loss function\n",
    "criterion_scratch = nn.CrossEntropyLoss()\n",
    "### TODO: select optimizer\n",
    "optimizer_scratch = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders_scratch = {\n",
    "    'train': train_loader,\n",
    "    'test': test_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(log_interval, model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        loss = F.nll_loss(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))           \n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data.to(device))\n",
    "            test_loss += F.nll_loss(output, target.to(device), reduction='sum').item() \n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.to(device).view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "import numpy as np\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "def train_mnist(trial):\n",
    "    cfg = { 'device' : \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "          'train_batch_size' : 64,\n",
    "          'test_batch_size' : 1000,\n",
    "          'n_epochs' : 1,\n",
    "          'seed' : 0,\n",
    "          'log_interval' : 100,\n",
    "          'save_model' : False,\n",
    "          'lr' : 0.001,\n",
    "          'momentum': 0.5,\n",
    "          'optimizer': optim.SGD,\n",
    "          'activation': F.relu}\n",
    "\n",
    "    torch.manual_seed(cfg['seed'])\n",
    "    train_loader, test_loader = get_mnist_loaders(cfg['train_batch_size'], cfg['test_batch_size'])\n",
    "    model = Net(cfg['activation'],trial).to(device)\n",
    "    optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
    "    for epoch in range(1, cfg['n_epochs'] + 1):\n",
    "        train(cfg['log_interval'], model, train_loader, optimizer, epoch)\n",
    "        test_accuracy = test(model, test_loader)\n",
    "\n",
    "    if cfg['save_model']:\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "      \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.312016\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.216830\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.124649\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.955338\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.678201\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.437773\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.239458\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.931220\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.933029\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.741264\n",
      "\n",
      "Test set: Average loss: 0.5964, Accuracy: 8609/10000 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance the accuracy with optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define NN class with optimzer\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,activation,trial):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        #Try different values\n",
    "        dropout_rate_1 = trial.suggest_float(\"dropout_rate_1\", 0, 1)\n",
    "        self.dropout1 = nn.Dropout2d(dropout_rate_1)\n",
    "        #Try different values\n",
    "        dropout_rate_2 = trial.suggest_float(\"dropout_rate_2\", 0, 1)\n",
    "        self.dropout2 = nn.Dropout2d(dropout_rate_2)\n",
    "        #Try different values\n",
    "        fc2_input_dim = trial.suggest_int(\"fc2_input_dim\", 40, 80)\n",
    "        self.fc1 = nn.Linear(9216, fc2_input_dim)\n",
    "        self.fc2 = nn.Linear(fc2_input_dim, 10)\n",
    "        self.activation = activation \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Create a convolutional neural network.\n",
    "    return train_mnist(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 23:50:21,583]\u001b[0m A new study created in memory with name: no-name-259fbf03-9d0c-4365-8bb3-f10cbd5ebed5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.357715\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.294753\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.137490\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.100519\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.979265\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.876369\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.678540\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.624928\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.637640\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.449244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 23:50:35,222]\u001b[0m Trial 0 finished with value: 82.05 and parameters: {'dropout_rate_1': 0.47813922956483357, 'dropout_rate_2': 0.8071444328023732, 'fc2_input_dim': 71}. Best is trial 0 with value: 82.05.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.0762, Accuracy: 8205/10000 (82%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.322586\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.219612\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.037623\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.956037\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.538672\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.339294\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.244622\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.945074\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.741721\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.669255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 23:50:49,122]\u001b[0m Trial 1 finished with value: 86.02 and parameters: {'dropout_rate_1': 0.6462543659366137, 'dropout_rate_2': 0.1099762086400825, 'fc2_input_dim': 42}. Best is trial 1 with value: 86.02.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5700, Accuracy: 8602/10000 (86%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.297442\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.316103\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.212835\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.188879\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.022063\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.973151\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.830922\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.872430\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.648466\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.612388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 23:51:02,897]\u001b[0m Trial 2 finished with value: 79.2 and parameters: {'dropout_rate_1': 0.831878021224476, 'dropout_rate_2': 0.6467126056993215, 'fc2_input_dim': 40}. Best is trial 1 with value: 86.02.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1917, Accuracy: 7920/10000 (79%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout_rate_1': 0.6462543659366137,\n",
       " 'dropout_rate_2': 0.1099762086400825,\n",
       " 'fc2_input_dim': 42}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
