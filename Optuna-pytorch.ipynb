{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, Optuna is used to optimize hyper-parameters, but as an example, let us directly optimize a quadratic function in an IPython shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function is what will be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(x):\n",
    "    return x\n",
    "def b(x):\n",
    "    return x\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float('x',0,1)\n",
    "    y = trial.suggest_float('y',0,1)\n",
    "    c = trial.suggest_categorical('z',[optim.RMSprop,optim.LBFGS])\n",
    "    return (x-2 + y) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the value of (x−2)2. Our goal is to find the value of x that minimizes the output of the objective function. This is the “optimization.” During the optimization, Optuna repeatedly calls and evaluates the objective function with different values of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Trial object corresponds to a single execution of the objective function and is internally instantiated upon each invocation of the function.\n",
    "\n",
    "The suggest APIs (for example, suggest_float()) are called inside the objective function to obtain parameters for a trial. suggest_float() selects parameters uniformly within the range provided. In our example, from −10 to 10.\n",
    "\n",
    "To start the optimization, we create a study object and pass the objective function to method optimize() as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-04 01:50:42,159]\u001b[0m A new study created in memory with name: no-name-90a54c37-cf22-4e86-9c0f-7541fda27a44\u001b[0m\n",
      "\u001b[33m[W 2020-11-04 01:50:42,162]\u001b[0m Trial 0 failed because of the following error: TypeError('optimizer can only optimize Tensors, but one of the params is int')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python37\\site-packages\\optuna\\study.py\", line 799, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-177-16a6526e7022>\", line 9, in objective\n",
      "    cc = c(params=[1,3])\n",
      "  File \"C:\\Users\\Asus\\Miniconda3\\lib\\site-packages\\torch\\optim\\lbfgs.py\", line 233, in __init__\n",
      "    super(LBFGS, self).__init__(params, defaults)\n",
      "  File \"C:\\Users\\Asus\\Miniconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 51, in __init__\n",
      "    self.add_param_group(param_group)\n",
      "  File \"C:\\Users\\Asus\\Miniconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 200, in add_param_group\n",
      "    \"but one of the params is \" + torch.typename(param))\n",
      "TypeError: optimizer can only optimize Tensors, but one of the params is int\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "optimizer can only optimize Tensors, but one of the params is int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-178-2feab99dcf6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                 self._optimize_sequential(\n\u001b[1;32m--> 339\u001b[1;33m                     \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m                 )\n\u001b[0;32m    341\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[0;32m    745\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    774\u001b[0m     ) -> None:\n\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-177-16a6526e7022>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'z'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLBFGS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\optim\\lbfgs.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, max_iter, max_eval, tolerance_grad, tolerance_change, history_size, line_search_fn)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0mhistory_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             line_search_fn=line_search_fn)\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLBFGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36madd_param_group\u001b[1;34m(self, param_group)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                 raise TypeError(\"optimizer can only optimize Tensors, \"\n\u001b[1;32m--> 200\u001b[1;33m                                 \"but one of the params is \" + torch.typename(param))\n\u001b[0m\u001b[0;32m    201\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"can't optimize a non-leaf Tensor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: optimizer can only optimize Tensors, but one of the params is int"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.8167804319008877, 'y': 0.8045517494297751, 'z': <function a at 0x0000029647E5D318>}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 23:33:34,556]\u001b[0m A new study created in memory with name: no-name-05e4a3b0-4c31-4377-b560-7dc05294ca29\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 23:33:34,559]\u001b[0m Trial 0 finished with value: 0.4224620415636302 and parameters: {'x': 0.8281157896717252, 'y': 0.5219134097813346}. Best is trial 0 with value: 0.4224620415636302.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 23:33:34,562]\u001b[0m Trial 1 finished with value: 0.8536605997062827 and parameters: {'x': 0.8143293286981494, 'y': 0.26173311945850075}. Best is trial 1 with value: 0.8536605997062827.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 23:33:34,563]\u001b[0m Trial 2 finished with value: 2.3746851389598636 and parameters: {'x': 0.164025351071456, 'y': 0.2949733059830345}. Best is trial 2 with value: 2.3746851389598636.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 23:33:34,565]\u001b[0m Trial 3 finished with value: 2.5604380700680793 and parameters: {'x': 0.041232570923020795, 'y': 0.358630538036691}. Best is trial 3 with value: 2.5604380700680793.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.041232570923020795, 'y': 0.358630538036691}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When used to search for hyper-parameters in machine learning, usually the objective function would return the loss or accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us clarify the terminology in Optuna as follows:\n",
    "\n",
    "Trial: A single call of the objective function\n",
    "\n",
    "Study: An optimization session, which is a set of trials\n",
    "\n",
    "Parameter: A variable whose value is to be optimized, such as x in the above example\n",
    "\n",
    "In Optuna, we use the study object to manage optimization. Method create_study() returns a study object. A study object has useful properties for analyzing the optimization outcome.\n",
    "\n",
    "To get the best parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.470793735864454"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get the best value\n",
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 0.6112550829175928, 'y': 0.7026008098684388}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best params\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=1, value=0.470793735864454, datetime_start=datetime.datetime(2020, 11, 3, 21, 18, 25, 744039), datetime_complete=datetime.datetime(2020, 11, 3, 21, 18, 25, 745036), params={'x': 0.6112550829175928, 'y': 0.7026008098684388}, distributions={'x': UniformDistribution(high=1, low=0), 'y': UniformDistribution(high=1, low=0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1, state=TrialState.COMPLETE)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best trial\n",
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=0, value=1.5086828166275867, datetime_start=datetime.datetime(2020, 11, 3, 21, 18, 25, 743040), datetime_complete=datetime.datetime(2020, 11, 3, 21, 18, 25, 743040), params={'x': 0.08653221865993654, 'y': 0.6851832798390528}, distributions={'x': UniformDistribution(high=1, low=0), 'y': UniformDistribution(high=1, low=0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE),\n",
       " FrozenTrial(number=1, value=0.470793735864454, datetime_start=datetime.datetime(2020, 11, 3, 21, 18, 25, 744039), datetime_complete=datetime.datetime(2020, 11, 3, 21, 18, 25, 745036), params={'x': 0.6112550829175928, 'y': 0.7026008098684388}, distributions={'x': UniformDistribution(high=1, low=0), 'y': UniformDistribution(high=1, low=0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1, state=TrialState.COMPLETE),\n",
       " FrozenTrial(number=2, value=1.6956906104507283, datetime_start=datetime.datetime(2020, 11, 3, 21, 18, 25, 747031), datetime_complete=datetime.datetime(2020, 11, 3, 21, 18, 25, 747031), params={'x': 0.32566767869187896, 'y': 0.3721454643437573}, distributions={'x': UniformDistribution(high=1, low=0), 'y': UniformDistribution(high=1, low=0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=2, state=TrialState.COMPLETE),\n",
       " FrozenTrial(number=3, value=2.0407518969141663, datetime_start=datetime.datetime(2020, 11, 3, 21, 18, 25, 748028), datetime_complete=datetime.datetime(2020, 11, 3, 21, 18, 25, 748028), params={'x': 0.02991942218059418, 'y': 0.5415316997917179}, distributions={'x': UniformDistribution(high=1, low=0), 'y': UniformDistribution(high=1, low=0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=3, state=TrialState.COMPLETE)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all trials \n",
    "study.trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By executing optimize() again, we can continue the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 21:22:17,820]\u001b[0m Trial 4 finished with value: 1.4578516550605316 and parameters: {'x': 0.16282839179581543, 'y': 0.6297563295777577}. Best is trial 1 with value: 0.470793735864454.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,822]\u001b[0m Trial 5 finished with value: 1.1627288295720606 and parameters: {'x': 0.918673522844393, 'y': 0.003027432561733434}. Best is trial 1 with value: 0.470793735864454.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,824]\u001b[0m Trial 6 finished with value: 0.7954999795411859 and parameters: {'x': 0.7695088836321555, 'y': 0.33858306082557843}. Best is trial 1 with value: 0.470793735864454.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,825]\u001b[0m Trial 7 finished with value: 0.2784199543587225 and parameters: {'x': 0.6730877999066328, 'y': 0.7992570529008828}. Best is trial 7 with value: 0.2784199543587225.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,827]\u001b[0m Trial 8 finished with value: 2.0740206536428203 and parameters: {'x': 0.03138077167792663, 'y': 0.5284731754361793}. Best is trial 7 with value: 0.2784199543587225.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,829]\u001b[0m Trial 9 finished with value: 0.17697138157169928 and parameters: {'x': 0.9112524774594283, 'y': 0.6680678563197058}. Best is trial 9 with value: 0.17697138157169928.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,837]\u001b[0m Trial 10 finished with value: 0.0005850131815088767 and parameters: {'x': 0.9985148023441425, 'y': 0.9772981519183378}. Best is trial 10 with value: 0.0005850131815088767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,846]\u001b[0m Trial 11 finished with value: 0.003560045642940849 and parameters: {'x': 0.9805989841665648, 'y': 0.9597348977852427}. Best is trial 10 with value: 0.0005850131815088767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,854]\u001b[0m Trial 12 finished with value: 0.00594750295702308 and parameters: {'x': 0.9569986561924559, 'y': 0.9658812883289393}. Best is trial 10 with value: 0.0005850131815088767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 21:22:17,862]\u001b[0m Trial 13 finished with value: 0.043399958315470784 and parameters: {'x': 0.7991795426505874, 'y': 0.9924938908355116}. Best is trial 10 with value: 0.0005850131815088767.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective,n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005850131815088767"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Optuna with deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "def get_mnist_loaders(train_batch_size,test_batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(datasets.MNIST('/files/',\n",
    "                                              train=True,download=True,\n",
    "                                              transform=transforms.Compose([\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                              ])),\n",
    "                        batch_size= train_batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(datasets.MNIST('/files/', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,test_loader = get_mnist_loaders(20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 28, 28])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = data, target \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define NN class\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,activation):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.activation = activation \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "model = Net(F.relu).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(log_interval, model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        loss = F.nll_loss(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))           \n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data.to(device))\n",
    "            test_loss += F.nll_loss(output, target.to(device), reduction='sum').item() \n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.to(device).view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "import numpy as np\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "def train_mnist(trial):\n",
    "    cfg = { 'device' : \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "          'train_batch_size' : 64,\n",
    "          'test_batch_size' : 1000,\n",
    "          'n_epochs' : 1,\n",
    "          'seed' : 0,\n",
    "          'log_interval' : 100,\n",
    "          'save_model' : False,\n",
    "          'lr' : 0.001,\n",
    "          'momentum': 0.5,\n",
    "          'optimizer': optim.SGD,\n",
    "          'activation': F.relu}\n",
    "    optimizer_value = trial.suggest_categorical('optimizer',[optim.SGD, optim.RMSprop])\n",
    "    torch.manual_seed(cfg['seed'])\n",
    "    train_loader, test_loader = get_mnist_loaders(cfg['train_batch_size'], cfg['test_batch_size'])\n",
    "    model = Net(cfg['activation'],trial).to(device)\n",
    "    optimizer = optimizer_value(model.parameters(), lr=cfg['lr'])\n",
    "    for epoch in range(1, cfg['n_epochs'] + 1):\n",
    "        train(cfg['log_interval'], model, train_loader, optimizer, epoch)\n",
    "        test_accuracy = test(model, test_loader)\n",
    "\n",
    "    if cfg['save_model']:\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "      \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing the classifier with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define NN class with optimzer\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,activation,trial):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        #Try different values\n",
    "        dropout_rate_1 = trial.suggest_float(\"dropout_rate_1\", 0, 1)\n",
    "        self.dropout1 = nn.Dropout2d(dropout_rate_1)\n",
    "        #Try different values\n",
    "        dropout_rate_2 = trial.suggest_float(\"dropout_rate_2\", 0, 1)\n",
    "        self.dropout2 = nn.Dropout2d(dropout_rate_2)\n",
    "        #Try different values\n",
    "        fc2_input_dim = trial.suggest_int(\"fc2_input_dim\", 40, 80)\n",
    "        self.fc1 = nn.Linear(9216, fc2_input_dim)\n",
    "        self.fc2 = nn.Linear(fc2_input_dim, 10)\n",
    "        self.activation = activation \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Create a convolutional neural network.\n",
    "    return train_mnist(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-04 01:53:40,279]\u001b[0m A new study created in memory with name: no-name-1288d177-5007-4148-a7f7-5a114a72ad2c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303064\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.224139\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.052420\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.939717\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.682366\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.506998\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.373453\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.154590\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.002761\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.018865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-04 01:54:00,487]\u001b[0m Trial 0 finished with value: 86.02 and parameters: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'dropout_rate_1': 0.5575685784855745, 'dropout_rate_2': 0.32591264617428684, 'fc2_input_dim': 46}. Best is trial 0 with value: 86.02.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6287, Accuracy: 8602/10000 (86%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.299859\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.234119\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.095125\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.432011\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.135249\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.067458\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.231411\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.118928\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.364296\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.226600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-04 01:54:16,335]\u001b[0m Trial 1 finished with value: 97.91 and parameters: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'dropout_rate_1': 0.5806917792270129, 'dropout_rate_2': 0.20284483158536126, 'fc2_input_dim': 67}. Best is trial 1 with value: 97.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0665, Accuracy: 9791/10000 (98%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.311454\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.206460\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.071437\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.949745\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.672349\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.401218\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.153758\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.826293\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.676942\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.643588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-04 01:54:30,402]\u001b[0m Trial 2 finished with value: 86.32 and parameters: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'dropout_rate_1': 0.23426539706779692, 'dropout_rate_2': 0.2564793260883751, 'fc2_input_dim': 66}. Best is trial 1 with value: 97.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5741, Accuracy: 8632/10000 (86%)\n",
      "\n",
      "Number of finished trials: 3\n",
      "Best trial:\n",
      "  Value: 97.91\n",
      "  Params: \n",
      "    optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "    dropout_rate_1: 0.5806917792270129\n",
      "    dropout_rate_2: 0.20284483158536126\n",
      "    fc2_input_dim: 67\n"
     ]
    }
   ],
   "source": [
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=3)\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout_rate_1': 0.6462543659366137,\n",
       " 'dropout_rate_2': 0.1099762086400825,\n",
       " 'fc2_input_dim': 42}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
